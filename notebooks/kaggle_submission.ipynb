{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSIRO Pasture Biomass Estimation - Submission Notebook\\n",
        "\\n",
        "This notebook generates predictions using the advanced multi-task ResNet50 model.\\n",
        "\\n",
        "**Model:** ResNet50 with multi-task learning + NDVI/Height fusion\\n",
        "**Best Validation Loss:** 148.45\\n",
        "**Training:** 67 epochs on competition dataset\\n",
        "\\n",
        "## Setup Instructions\\n",
        "\\n",
        "1. **Upload Model Checkpoint as Dataset:**\\n",
        "   - Create a new Kaggle dataset named `csiro-biomass-model`\\n",
        "   - Upload `models/checkpoints/best_multitask_model.pth` (311MB)\\n",
        "   - Make dataset public\\n",
        "\\n",
        "2. **Add Dataset to Notebook:**\\n",
        "   - Go to Notebook settings (\u2699\ufe0f)\\n",
        "   - Add dataset: `csiro-biomass-model`\\n",
        "   - Add dataset: `csiro-biomass` (competition data)\\n",
        "\\n",
        "3. **Configure Notebook:**\\n",
        "   - Internet: OFF\\n",
        "   - GPU: ON (recommended) or CPU\\n",
        "   - Accelerator: T4 GPU (free) or P100 (free)\\n",
        "\\n",
        "4. **Run and Submit:**\\n",
        "   - Click \"Run All\"\\n",
        "   - Once completed, click \"Save Version\" \u2192 \"Save & Run All\"\\n",
        "   - Click \"Submit\" button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom pathlib import Path\nimport os\n\n# Set random seed\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n\"\"\"\nAdvanced multi-task model for CSIRO competition.\nPredicts all 5 target types simultaneously with separate heads.\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\ntry:\n    import timm\n    TIMM_AVAILABLE = True\nexcept ImportError:\n    TIMM_AVAILABLE = False\n\n\nclass AdvancedMultiTaskBiomassModel(nn.Module):\n    \"\"\"\n    Advanced multi-task model that predicts all 5 target types simultaneously.\n    Uses shared backbone with separate regression heads for each target type.\n    \"\"\"\n    \n    def __init__(self, model_name='resnet50', pretrained=True, dropout=0.5):\n        \"\"\"\n        Initialize advanced multi-task model.\n        \n        Args:\n            model_name: Base model name\n            pretrained: Use pretrained weights\n            dropout: Dropout rate\n        \"\"\"\n        super().__init__()\n        \n        self.target_types = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n        \n        # Backbone\n        if TIMM_AVAILABLE:\n            try:\n                self.backbone = timm.create_model(\n                    model_name,\n                    pretrained=pretrained,\n                    num_classes=0,\n                    global_pool=''\n                )\n                with torch.no_grad():\n                    dummy_input = torch.randn(1, 3, 224, 224)\n                    features = self.backbone(dummy_input)\n                    if isinstance(features, tuple):\n                        features = features[0]\n                    if len(features.shape) == 4:\n                        gap = nn.AdaptiveAvgPool2d(1)\n                        features = gap(features)\n                        self.feature_dim = features.shape[1]\n                    else:\n                        self.feature_dim = features.shape[-1]\n            except Exception:\n                model = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n                self.backbone = nn.Sequential(*list(model.children())[:-2])\n                self.feature_dim = 2048\n        else:\n            model = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n            self.backbone = nn.Sequential(*list(model.children())[:-2])\n            self.feature_dim = 2048\n        \n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        \n        # Shared feature extractor\n        self.shared_features = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(self.feature_dim, 1024),\n            nn.ReLU(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(dropout),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n        )\n        \n        # Feature fusion: combine image features with NDVI and Height\n        self.feature_fusion = nn.Sequential(\n            nn.Linear(512 + 2, 512),  # +2 for NDVI and Height\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n        )\n        \n        # Separate heads for each target type\n        self.target_heads = nn.ModuleDict()\n        for target_type in self.target_types:\n            self.target_heads[target_type] = nn.Sequential(\n                nn.Dropout(dropout / 2),\n                nn.Linear(512, 256),\n                nn.ReLU(),\n                nn.BatchNorm1d(256),\n                nn.Dropout(dropout / 4),\n                nn.Linear(256, 1)\n            )\n    \n    def forward(self, x, ndvi=None, height=None, target_type=None):\n        \"\"\"\n        Forward pass.\n        \n        Args:\n            x: Input images\n            ndvi: NDVI values (optional)\n            height: Height values (optional)\n            target_type: If specified, only return prediction for this target type\n            \n        Returns:\n            Dictionary of predictions for each target type, or single prediction\n        \"\"\"\n        # Extract features\n        features = self.backbone(x)\n        if len(features.shape) == 4:\n            features = self.global_pool(features)\n            features = features.view(features.size(0), -1)\n        elif len(features.shape) == 3:\n            features = features.mean(dim=1)\n        else:\n            features = features.flatten(1) if len(features.shape) > 2 else features\n        \n        if features.shape[1] != self.feature_dim:\n            features = features[:, :self.feature_dim]\n        \n        # Shared features\n        shared = self.shared_features(features)\n        \n        # Fuse with NDVI and Height if provided\n        if ndvi is not None and height is not None:\n            # Normalize features\n            ndvi_norm = (ndvi - 0.5) / 0.3  # Approximate normalization\n            height_norm = (height - 15.0) / 10.0  # Approximate normalization\n            aux_features = torch.stack([ndvi_norm, height_norm], dim=1)\n            fused = torch.cat([shared, aux_features], dim=1)\n            fused = self.feature_fusion(fused)\n        else:\n            fused = shared\n        \n        # Predictions for all target types\n        predictions = {}\n        for target_type_name in self.target_types:\n            pred = self.target_heads[target_type_name](fused)\n            predictions[target_type_name] = pred.squeeze(-1)\n        \n        if target_type:\n            return predictions.get(target_type, predictions[self.target_types[0]])\n        \n        return predictions\n\n\n\n# TestDataset class\nclass TestDataset(Dataset):\n    def __init__(self, test_df, image_dir, transform):\n        self.test_df = test_df\n        self.image_dir = Path(image_dir)\n        self.transform = transform\n        self.unique_images = test_df['image_path'].unique()\n        \n    def __len__(self):\n        return len(self.unique_images)\n    \n    def __getitem__(self, idx):\n        img_path = self.unique_images[idx]\n        full_path = self.image_dir / img_path\n        \n        try:\n            image = Image.open(full_path).convert('RGB')\n            image = np.array(image)\n        except:\n            image = np.zeros((224, 224, 3), dtype=np.uint8)\n        \n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed['image']\n        \n        return {'image': image, 'image_path': img_path}\n\n# Load test data\nprint(\"\\n\ud83d\udcc1 Loading data...\")\ntest_df = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\nprint(f\"Test samples: {len(test_df)}\")\n\n# Load model\nprint(\"\\n\ud83e\udd16 Loading model...\")\nmodel = AdvancedMultiTaskBiomassModel(pretrained=False).to(device)\n\n# Try to load checkpoint\ncheckpoint_paths = [\n    '/kaggle/input/csiro-biomass-model/best_multitask_model.pth',\n    '/kaggle/input/csiro-biomass-model/models/checkpoints/best_multitask_model.pth',\n    '/kaggle/input/csiro-biomass-model/checkpoints/best_multitask_model.pth',\n]\n\ncheckpoint_loaded = False\nfor checkpoint_path in checkpoint_paths:\n    if os.path.exists(checkpoint_path):\n        print(f\"Loading checkpoint from: {checkpoint_path}\")\n        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        checkpoint_loaded = True\n        print(f\"\u2705 Model loaded! Best val loss: {checkpoint.get('val_loss', 'N/A')}\")\n        break\n\nif not checkpoint_loaded:\n    print(\"\u26a0\ufe0f  No checkpoint found. Using pretrained ImageNet weights only.\")\n    model = AdvancedMultiTaskBiomassModel(pretrained=True).to(device)\n\nmodel.eval()\n\n# Prepare test data\nprint(\"\\n\ud83d\udd27 Preparing test data...\")\ntransform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\n# Find image directory\nimage_dir_candidates = [\n    '/kaggle/input/csiro-biomass/test',\n    '/kaggle/input/csiro-biomass/train',\n    '/kaggle/input/csiro-biomass',\n]\n\nimage_dir = '/kaggle/input/csiro-biomass'\nfor candidate in image_dir_candidates:\n    if os.path.exists(candidate):\n        test_img_path = test_df['image_path'].iloc[0]\n        if os.path.exists(os.path.join(candidate, test_img_path)) or os.path.exists(os.path.join(candidate, os.path.basename(test_img_path))):\n            image_dir = candidate\n            break\n\nprint(f\"Using image directory: {image_dir}\")\n\ntest_dataset = TestDataset(test_df, image_dir, transform)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n\n# Generate predictions\nprint(\"\\n\ud83d\udd2e Generating predictions...\")\nimage_predictions = {}\n\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch['image'].to(device)\n        predictions = model(images)\n        \n        batch_size = len(batch['image_path'])\n        for i in range(batch_size):\n            img_path = batch['image_path'][i]\n            pred_dict = {\n                target_type: float(predictions[target_type][i].cpu().item())\n                for target_type in model.target_types\n            }\n            image_predictions[img_path] = pred_dict\n\n# Create submission\nprint(\"\\n\ud83d\udcdd Creating submission file...\")\nsubmission_rows = []\n\nfor _, row in test_df.iterrows():\n    img_path = row['image_path']\n    target_name = row['target_name']\n    \n    if img_path in image_predictions:\n        pred = image_predictions[img_path].get(target_name, 0.0)\n    else:\n        pred = 0.0\n    \n    pred = max(0.0, pred)\n    \n    submission_rows.append({\n        'sample_id': row['sample_id'],\n        'target': pred\n    })\n\nsubmission_df = pd.DataFrame(submission_rows)\n\n# Apply constraint: Dry_Total = sum of components\nfor img_path in test_df['image_path'].unique():\n    img_rows = test_df[test_df['image_path'] == img_path]\n    sub_rows = submission_df[submission_df['sample_id'].isin(img_rows['sample_id'])]\n    \n    if len(sub_rows) >= 4:\n        clover_mask = sub_rows['sample_id'].str.contains('Dry_Clover_g', na=False)\n        dead_mask = sub_rows['sample_id'].str.contains('Dry_Dead_g', na=False)\n        green_mask = sub_rows['sample_id'].str.contains('Dry_Green_g', na=False)\n        total_mask = sub_rows['sample_id'].str.contains('Dry_Total_g', na=False)\n        \n        if clover_mask.any() and dead_mask.any() and green_mask.any() and total_mask.any():\n            clover_val = sub_rows[clover_mask]['target'].values[0]\n            dead_val = sub_rows[dead_mask]['target'].values[0]\n            green_val = sub_rows[green_mask]['target'].values[0]\n            calculated_total = clover_val + dead_val + green_val\n            \n            submission_df.loc[sub_rows[total_mask].index[0], 'target'] = calculated_total\n\n# Round to 6 decimal places\nsubmission_df['target'] = submission_df['target'].round(6)\n\n# Save submission\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\n\u2705 Submission file created: submission.csv\")\nprint(f\"\\n\ud83d\udcca Submission Statistics:\")\nprint(f\"   Total predictions: {len(submission_df)}\")\nprint(f\"   Target range: {submission_df['target'].min():.2f} - {submission_df['target'].max():.2f}\")\nprint(f\"   Mean: {submission_df['target'].mean():.2f}\")\nprint(f\"   Std: {submission_df['target'].std():.2f}\")\n\nprint(\"\\n\ud83c\udfaf Predictions by target type:\")\nfor target_name in sorted(test_df['target_name'].unique()):\n    mask = test_df['target_name'] == target_name\n    preds = submission_df[mask]['target']\n    if len(preds) > 0:\n        print(f\"   {target_name}: {preds.values[0]:.6f}\")\n\nprint(\"\\n\u2728 Ready to submit!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}